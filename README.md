# BERT Based Email Sorting for Strategic Segments

In this project, we have a dataset of approximately 1700 emails, and our objective is to classify the email into one of six predefined genre classes. The dataset consists of eight subfolders, each representing a class, with only the first six used for classification. Email labels have been extracted directly from subfolder names, and the emails have been read as strings.

We have created a pandas data frame with labels and email content. Initial analysis has revealed significant class imbalance, which we have addressed later. We have used the ‘Parser’ class from the ‘email.parser’ module to extract the text and have concatenated the email subject and main message. Quoted messages (e.g., replies or forwarded emails) have been removed using a custom function that identifies keywords like ‘Forwarded by’ and symbols such as ‘<’ or ‘>>’. The cleaned data have been converted to lowercase, and we have removed numbers, punctuation, URLs, stopwords, and extra whitespaces.

The dataset has been splitted into training, validation, and test sets in an 80:10:10 ratio. To address class imbalance in the training set, we have used ‘ContextualWordEmbsAug’ class from the ‘nlpaug’ library to perform word-level augmentation, upsampling all minority classes to match the size of the largest class. The augmented data have been saved for reuse due to the timeintensive augmentation process. Further, we have performed lemmatization on our data, and then have done tokenization using ‘BertTokenizer’ from Hugging Face’s ‘Transformers’ library with ‘bert-base-uncased’ configuration.

For model training, we have used ‘BertForSequenceClassification’ with ‘bert-base-uncased’ configuration and six output labels. The dataset has been prepared using ‘TensorDataset’ and passed to ‘DataLoader’ with a batch size of 32. We have trained the model for three epochs using the Adam optimizer and the Cross Entropy loss with learning rate set to 3e-5. Finally, on testing, we have achieved an Accuracy and F1-score of around 91.57%
